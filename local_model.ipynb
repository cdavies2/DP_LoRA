{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "a30e97fe-15b9-47b5-afd9-530c9602c796",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/scratch/ac.cdavies/cdavies_Unit_Tests/.venv/lib/python3.12/site-packages/tqdm/auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "' mistral/models--mistralai--Mistral-7B-Instruct-v0.1/snapshots/2dcff66eac0c01dc50e4c41eea959968232187fe/config.json'"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from huggingface_hub import hf_hub_download\n",
    "\n",
    "hf_hub_download(repo_id=\"mistralai/Mistral-7B-Instruct-v0.1\", filename=\"config.json\", cache_dir=\" mistral\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "49039f82-9860-457a-a2ee-dd0cae2b176e",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-03-19 15:39:17.932658: E external/local_xla/xla/stream_executor/cuda/cuda_fft.cc:467] Unable to register cuFFT factory: Attempting to register factory for plugin cuFFT when one has already been registered\n",
      "WARNING: All log messages before absl::InitializeLog() is called are written to STDERR\n",
      "E0000 00:00:1742398757.966669  937027 cuda_dnn.cc:8579] Unable to register cuDNN factory: Attempting to register factory for plugin cuDNN when one has already been registered\n",
      "E0000 00:00:1742398757.977466  937027 cuda_blas.cc:1407] Unable to register cuBLAS factory: Attempting to register factory for plugin cuBLAS when one has already been registered\n",
      "W0000 00:00:1742398758.019643  937027 computation_placer.cc:177] computation placer already registered. Please check linkage and avoid linking the same target more than once.\n",
      "W0000 00:00:1742398758.019704  937027 computation_placer.cc:177] computation placer already registered. Please check linkage and avoid linking the same target more than once.\n",
      "W0000 00:00:1742398758.019709  937027 computation_placer.cc:177] computation placer already registered. Please check linkage and avoid linking the same target more than once.\n",
      "W0000 00:00:1742398758.019713  937027 computation_placer.cc:177] computation placer already registered. Please check linkage and avoid linking the same target more than once.\n",
      "2025-03-19 15:39:18.032606: I tensorflow/core/platform/cpu_feature_guard.cc:210] This TensorFlow binary is optimized to use available CPU instructions in performance-critical operations.\n",
      "To enable the following instructions: AVX2 FMA, in other operations, rebuild TensorFlow with the appropriate compiler flags.\n",
      "Loading checkpoint shards: 100%|██████████████████████████████████████████████████████████████████████████████| 2/2 [00:00<00:00,  2.11it/s]\n",
      "IOStream.flush timed out\n",
      "IOStream.flush timed out\n"
     ]
    }
   ],
   "source": [
    "from transformers import AutoModelForCausalLM\n",
    "#config=AutoConfig.from_pretrained(\" mistral/models--mistralai--Mistral-7B-Instruct-v0.1/snapshots/2dcff66eac0c01dc50e4c41eea959968232187fe/config.json\")\n",
    "model=AutoModelForCausalLM.from_pretrained(\"mistralai/Mistral-7B-Instruct-v0.1\", num_labels=3, torch_dtype=\"auto\")\n",
    "model.save_pretrained(\"mis_model\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "fc3cf242-dfd0-417e-ad9e-2440f932dcca",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Loading checkpoint shards: 100%|██████| 3/3 [01:43<00:00, 34.52s/it]\n"
     ]
    }
   ],
   "source": [
    "m2=AutoModelForCausalLM.from_pretrained(\"mis_model\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "e3de253f-7ba3-4bfc-a119-86baa0769e07",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "('mis_token/tokenizer_config.json',\n",
       " 'mis_token/special_tokens_map.json',\n",
       " 'mis_token/tokenizer.json')"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from transformers import AutoTokenizer\n",
    "tokenizer=AutoTokenizer.from_pretrained(\"mistralai/Mistral-7B-Instruct-v0.1\")\n",
    "tokenizer.save_pretrained(\"mis_token\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "555b99c7-968f-4302-af51-548c05deb7bf",
   "metadata": {},
   "outputs": [],
   "source": [
    "t2=AutoTokenizer.from_pretrained(\"mis_token\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "accfcbd6-96e5-4cdf-99e2-3f5fe396b33d",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Device set to use cpu\n",
      "Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'role': 'assistant', 'content': \" Prompt injection is a type of security vulnerability that can occur in web applications that use user input to generate dynamic content. It occurs when an attacker is able to inject malicious code into the user input, which is then executed by the web application.\\n\\nThe attacker can use various techniques to inject malicious code, such as SQL injection, cross-site scripting (XSS), and command injection. These techniques allow the attacker to manipulate the web application's behavior and potentially gain unauthorized access to sensitive data or perform malicious actions on behalf of the user.\\n\\nTo prevent prompt injection attacks,\"}\n"
     ]
    }
   ],
   "source": [
    "from transformers import pipeline\n",
    "pipe=pipeline(\"text-generation\", model=m2, tokenizer=t2) \n",
    "#the text generation pipeline has an automated pipeline for chat inputs\n",
    "messages=[\n",
    "    {\n",
    "        \"role\": \"system\", \"content\": \"\"\"You are an assistant teaching at a university level,\n",
    "                Use technical and complex terms in your explanation \"\"\"},\n",
    "                {\"role\": \"user\", \"content\": \"Please explain what a prompt injection is\"}\n",
    "]\n",
    "print(pipe(messages, max_new_tokens=128)[0]['generated_text'][-1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dda0e827-05cb-41d7-8f5b-f7a8ff6eec31",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
